ğŸ¥ Multimodal Medical AI System

A production-ready Multimodal Disease Prediction System that integrates:

ğŸ©» Chest X-ray imaging

ğŸ“ Clinical text reports

ğŸ§  Medical Knowledge Graph (Neo4j)

ğŸ”„ Cross-modal attention fusion

ğŸ“Š Uncertainty estimation (Monte Carlo Dropout)

ğŸ”¥ Explainability (Grad-CAM)

ğŸš€ FastAPI inference API

ğŸ³ Dockerized deployment

âš ï¸ Disclaimer

This project is intended strictly for research and educational purposes.
It is NOT approved for medical diagnosis or clinical use.

ğŸ¯ Objective

Medical decision-making often requires combining:

Radiology imaging

Clinical documentation

Prior medical knowledge

This system builds a unified AI model that fuses:

Vision features (Chest X-ray via DenseNet121)

Text embeddings (ClinicalBERT)

Knowledge graph embeddings (Neo4j)

to perform multi-label disease prediction with:

Uncertainty estimation

Model explainability

API-based deployment

ğŸ— System Architecture
ğŸ”¹ Vision Encoder

DenseNet121 backbone

Pretrained on ImageNet

Multi-label classifier

ğŸ”¹ Text Encoder

ClinicalBERT (emilyalsentzer/Bio_ClinicalBERT)

Contextual medical text embeddings

ğŸ”¹ Knowledge Graph

Neo4j database

Diseaseâ€“Symptomâ€“Treatment relationships

Embedding projection layer

ğŸ”¹ Fusion Module

Multihead cross-attention

Shared embedding space

Final classification head

ğŸ”¹ Uncertainty Module

Monte Carlo Dropout

Returns predictive mean + variance

ğŸ”¹ Explainability

Grad-CAM heatmaps for visual reasoning

ğŸ“‚ Project Structure
medical-multimodal-ai/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ inference.py
â”‚   â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ vision.py
â”‚   â”‚   â”œâ”€â”€ text.py
â”‚   â”‚   â”œâ”€â”€ kg.py
â”‚   â”‚   â”œâ”€â”€ fusion.py
â”‚   â”‚   â”œâ”€â”€ multimodal.py
â”‚   â”‚   â””â”€â”€ uncertainty.py
â”‚   â”‚
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”‚   â”œâ”€â”€ kg_service.py
â”‚   â”‚   â””â”€â”€ explainability.py
â”‚
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ dataset.py
â”‚   â”œâ”€â”€ train.py
â”‚   â””â”€â”€ evaluate.py
â”‚
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ Medical_AI_Assistant.pdf
â”‚
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ environment.yml
â””â”€â”€ README.md
ğŸ“„ Documentation

Full system design and architecture:

docs/Medical_AI_Assistant.pdf

Includes:

Problem framing

Dataset selection

Model architecture

Knowledge graph design

Deployment strategy

Research extensions

ğŸ§ª Environment Setup (Anaconda)
1ï¸âƒ£ Create Environment
conda create -n medical-ai python=3.10 -y
conda activate medical-ai
2ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

Or recreate environment:

conda env create -f environment.yml
conda activate medical-ai
ğŸš€ Running the API

Start FastAPI server:

uvicorn app.main:app --reload

Open Swagger UI:

http://localhost:8000/docs
ğŸ³ Docker Deployment

Run full stack (API + Neo4j):

docker-compose up --build

Services:

API â†’ http://localhost:8000

Neo4j â†’ http://localhost:7474

ğŸ“Š API Output Example
{
  "prediction": [0.12, 0.87, ...],
  "uncertainty": [0.03, 0.15, ...],
  "disclaimer": "Research use only. Not for diagnosis."
}
ğŸ“ˆ Evaluation Metrics

AUROC (per class)

Macro-F1 score

Precision / Recall

Expected Calibration Error (ECE)

â˜ï¸ Deployment Options

AWS EC2 (GPU enabled)

GCP Cloud Run

Azure App Service

Kubernetes cluster

ğŸ” Production Hardening (Recommended)

HTTPS via NGINX

JWT authentication

Rate limiting

MLflow model registry

Prometheus + Grafana monitoring

GPU inference server

ğŸ”¬ Research Extensions

Graph Neural Networks (GNN) for KG reasoning

Contrastive multimodal pretraining

Active learning pipelines

Federated hospital training

Differential privacy

ğŸ§  Tech Stack

PyTorch

HuggingFace Transformers

Neo4j

FastAPI

Docker

Monte Carlo Dropout

Grad-CAM

ğŸ“œ License

Add your preferred license (MIT recommended).

ğŸ‘¨â€ğŸ’» Author

Abhishek Kumar
AI Systems | Backend Engineering | Distributed Systems
